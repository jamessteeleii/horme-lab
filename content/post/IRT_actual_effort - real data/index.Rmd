---
title: "Actual Effort in Cognitive Tasks (pt 2)"
subtitle: Some examples using Item Response Theory with real data
date: '2022-03-15T16:06:15Z'
output:
  html_document: 
    df_print: paged
  pdf_document: 
tags: []
categories: []
summary: In this post I get hold of some real data to test out my idea of using Item Response Theory for operationalising actual effort
lastmod: '2022-03-15T16:06:15Z'
featured: no
draft: no
image:
  caption: ''
focal_point: ''
preview_only: no
projects: []
authors: []
---
```{r, echo=FALSE, message=FALSE}

## Setup
library(tidyverse)
library(brms)
library(ordbetareg)
library(patchwork)
library(tidybayes)

```

### _Recap_
You can read part 1 of my exploration of using Item Response Theory (IRT) for operationalisation of actual effort in cognitive tasks [here](https://www.hormelab.com/post/irt_actual_effort/).

But here's a very quick TLDR recap of the thinking from it's conclusion:

  > "Key assumptions underlying IRT models and their parameters, _ability_ and _difficulty_, map conceptually well onto the assumed primitives, _capacity_ and _demands_, in my definition of effort. Given this, IRT models seem like a useful approach to operationalisation of _actual effort_ in cognitive tasks. In fact, using the example of a test involving lifting weights where we actually know a persons underlying ability/capacity and the difficulty/demands of each item in the test, the estimates of effort that result from an IRT model are pretty reasonable estimates of the actual effort we could calculate from direct measurements."

In the post, I used the analogy of testing the ability of 'strength' through lifting different loads and fit a 1-parameter logistic (1PL, or Rasch model) to some simulated data representing people with varying strength levels lifting different loads successfully or not depending on this. This toy example demonstrated quite nicely (if I do say so myself) that in principle we can use IRT models to estimate the actual effort required for a given person performing a given task/item. As a result, I think it could be a promising approach to exploring effort psychophysics in cognitive tasks i.e., the relationship between actual effort, and perception of effort.

But how does it work out when we introduce it to some real data? I got hold of a dataset where I was able to fit IRT models to the cognitive tasks performed, and where they had also captured some operationalisation of perception of effort.

### _Measurement scale issues_
Before I get to the actual dataset, we first need to talk about the issues with IRT models for my ideas about estimating effort as:

  $$\theta_{j}=C_{A(j)}$$
  $$\beta_{i}=D_{A(i)}$$

  $$\beta_{i} \leq \theta_{j} \Rightarrow E_{A(ji,IRT)} = \frac{ 
    \beta_{i}}
{\theta_{j}} \times 100%$$
  
  $$\beta_{i} > \theta_{j} \Rightarrow E_{A(ji,IRT)} = 100%$$
  
Where, for each person we test $j(j=1,...,J)$, and each item in a test they complete $i(i=1,...,I)$, $\theta_{j}$ is the IRT estimated person latent ability, $C_{A(j)}$ is the actual capacity, $\beta_{i}$ is the IRT estimated item difficulty parameter, $D_{A(i)}$ is the actual item demands, and $E_{A(ji,IRT)}$ is the actual effort that it is estimated from the IRT model.

A problem is that common IRT models are typically estimated on the $logit$ scale which ranges $-\infty,\infty$. This poses some problems for us when it comes to calculating $E_{A(ji,IRT)}$ from the ratio of $\beta_{i}$ to $\theta_{j}$ as $logit$ scale does not have ratio properties. Now, I did mention that there are various ways of transforming the $logit$ scale that both preserves the underlying probabilities for a given $\theta$ completing a given item with difficulty $\beta$. For example, the 1PL model can undergo linear transformation without altering the underlying mathematical model and we can have $\theta_{transf}$ and $\beta_{transf}$. This gave me the idea for the weight lifting toy example. Given I had the $C_{A(j)}$ because I simulated it, and had also chosen the $D_{A(i)}$ which these simulated people would try to meet, and all in its raw units (kg), once I had fit the 1PL model I could fit simple linear models to transform $\theta_{j}$ and $\beta_{i}$ back to the raw kg units $\theta_{j(transf)}$ and $\beta_{i(transf)}$.

However, I hit a bit of a snag thinking through this with typical cognitive tasks. It's not as simple as with my toy example to put $\theta_{j}$ and $\beta_{i}$ onto ratio scales in a meaningful way... For example, It seems ontologically odd to me to have ability on the logit scale. I mean, does anyone really conceptualise $\theta_{j}$ in some task as really ranging from $-\infty,\infty$? Do we not think there's at least some floor (i.e., you can't do any difficulty item)? Also, transformation back to sum scores, or even proportions accurate (akin to the test characteristics curve) seems _odd_ for $\beta_{i}$. 

_Odd_? 

Oh, then it suddenly hit me... $\theta_{j}$ and $\beta_{i}$ could be placed back onto ratio scales in a meaningful way: the _odds_ scale.

This approach is somewhat limited to the application of 1PL/Rasch type IRT models[^1] but it's something to start with. 

Under the odds formulation of the 1PL/Rasch model we estimate actual effort in cognitive tasks as:

$$exp(\theta_{j})=C_{A(j)}$$
  $$exp(\beta_{i})=D_{A(i)}$$

  $$exp(\beta_{i}) \leq exp(\theta_{j}) \Rightarrow E_{A(ji,IRT)} = \frac{ 
    exp(\beta_{i})}
{exp(\theta_{j})} \times 100%$$
  
  $$exp(\beta_{i}) > exp(\theta_{j}) \Rightarrow E_{A(ji,IRT)} = 100%$$

Working with the assumption as I do that... 

  >"...the perception of effort appears at best a coarsegrained representation of actual effort which is probably a result of the introduction of ‘noise’ into the signal from both the sensory systems, and the perceptual system. As such, although the directional patterns of perception of effort often follow those we would expect based upon actual effort, they are ‘fuzzy’ and inaccurate representations of reality."[^2]

We'd expect to at the very least see positive directional relationships between our IRT operationalisation of actual (objective) effort (i.e., $E_{A(ji,IRT)}$) and operationalisations of perception of (subjective) effort, or subjective effort.

So let's take a look at an example dataset.

### _N-Back tasks, NASA-TLX, and Effort Discounting_

Andrew Westbrook was kind enough to share with me all the data from his 2013 PloS One study with Daria Kester and Todd Braver:

<center>

[_What Is the Subjective Cost of Cognitive Effort? Load, Trait, and Aging Effects Revealed by Economic Preference_](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0068210)

</center>

In this study both young and old adults performed the N-Back task[^3] over varying difficulty levels (1-6-Back). They also captured two different operationalisations _related_ to the subjective nature of effort. Firstly, they captured the NASA Task Load Index (NASA-TLX)[^4] which here I assume is an operationalisation of the perception of effort i.e., the phenomenological experience. Secondly, they also determined the subjective value/cost of effort using a cognitive effort discounting paradigm[^5] which I'm not sure is wholly reflective of the perception of effort _per se_[^6] but is interesting to explore nonetheless. So in all we have a cognitive task (N-Back) which we can apply an IRT model to in order to operationalise the actual (objective) effort, and a couple of different operationalisation of the perception of (subjective) effort. 

So firstly let's fit the 1PL model to the N-Back data treating each level (1-6) as an item. Here's the Item Characteristic Curves across the items:

```{r, echo=FALSE, message=FALSE}
# 
# setwd("C:/Users/James/Dropbox/Research/Understanding Effort - and other perceptual phenomena/Horme Lab/Website/horme-lab/content/post/IRT_actual_effort - real data/datasets/Westbrook et al. 2013")
# 
# # load and prepare data
# nback_a_dat <- read.csv("2013_Nback_a.csv")
# nback_b_dat <- read.csv("2013_Nback_b.csv")
# 
# nback_dat <- rbind(nback_a_dat, nback_b_dat) %>%
#   rename("person" = Subject,
#          "item" = stimcol,
#          "response" = TrialAcc) %>%
#   mutate(person = factor(person),
#          item = factor(item))
# 
# nback_dat$item <- recode(nback_dat$item, "black" = "1", "red" = "2", "blue" = "3", "purple" = "4", "yellow" = "5", "brown" = "6")
# 
# SV_dat <- read.csv("SVtbl.csv")
# 
# SV_dat <- SV_dat %>%
#   rename("person" = Subject,
#          "item" = Task) %>%
#   mutate(person = factor(person),
#          item = factor(item),
#          SV_effort = 1-SV)
# 
# AUC_dat <- read.csv("AUC_age_income_subjectiveReport.csv")
# 
# AUC_dat <- AUC_dat %>%
#   rename("person" = Subject) %>%
#   mutate(person = factor(person))
# 
# NASA_dat <- read.csv("NASA_TLX.csv")
# 
# NASA_dat <- NASA_dat %>%
#   rename("person" = Participant,
#          "item" = Task) %>%
#   mutate(person = factor(person),
#          item = factor(item))
# 
# NASA_dat$item <- recode(NASA_dat$item, "BLK" = "1", "RED" = "2", "BLU" = "3", "PRP" = "4")
# 
# ## 1PL model
# 
# formula_1pl <- bf(
#   formula = response ~ 1 + (1 | item) + (1 | person),
#   family = brmsfamily("bernoulli", link = "logit")
# )
# 
# prior_1pl <-
#   prior("normal(0, 2)", class = "Intercept") +
#   prior("normal(0, 3)", class = "sd", group = "person") +
#   prior("normal(0, 3)", class = "sd", group = "item")
# 
# fit_1pl <- brm(
#   formula = formula_1pl,
#   data = nback_dat,
#   prior = prior_1pl,
#   chains = 4,
#   iter = 3000, warmup = 1000,
#   cores = 4,
#   control = list(adapt_delta = 0.95), inits = 0
# )
# 
# post <- posterior_samples(fit_1pl)
# 
# post <- post %>%
#   select(b_Intercept, starts_with("r_item")) %>%
#   mutate(iter = 1:n()) %>%
#   pivot_longer(starts_with("r_item"), names_to = "item", values_to = "beta") %>%
#   mutate(item = str_extract(item, "\\d+"))
# 
# post_icc <- post %>%
#   tidyr::expand(nesting(iter, b_Intercept, item, beta),
#                 theta = seq(from = -6, to = 6, length.out = 100)) %>%
#   mutate(p = inv_logit_scaled(b_Intercept + beta + theta)) %>%
#   group_by(theta, item) %>%
#   summarise(p = mean(p))
# 
# 
# icc_p <- post_icc %>%
#   ggplot(aes(x = theta, y = p, color = item)) +
#   geom_line() +
#   # scale_color_viridis_d(option = "H") +
#   scale_color_manual(values = c("black", "red", "blue", "purple", "yellow", "brown")) +
#   labs(title = "ICCs for the 1PL",
#        subtitle = "Each curve is based on the posterior mean.",
#        x = expression(theta~('ability on the logit scale')),
#        y = expression(italic(p)(y==1)),
#        color = "Item (N-Back)") +
#   theme_classic() +
#   theme(legend.text = element_text(size = 8),
#         legend.title = element_text(size=10))
# 
# icc_p

```

Nice. The 1PL model shows what we would expect from increasing N-Back: that the difficulty of each item increases with the N trials ago that someone is trying to remember.

From this we can pull out the random effects for person and item, $\theta_{j}$ and $\beta_{i}$, and then we can exponentiate them to put them back on the odds scale to calculate $E_{A(ji,IRT)}$. Then we rejoin it with the effort scale from the NASA-TLX, and the subjective cost of effort determined from the effort discounting paradigm, and can begin to model the relationship between $E_{A(ji,IRT)}$ and both these operationlisations of perception of (subjective) effort.

First we will look at the NASA-TLX data. Now, the NASA-TLX is an ordinal scale and so we might consider using cummulative ordinal regression on the probit scale. But this model assumes that the data arises from unbounded normal distributions where our underlying latent variable of perception of effort is conceptually bounded. So we should use a model to reflect that such as ordered beta regression[^7]. Similarly to the previous post we fit a mixed effects model with random intercepts and slopes to explore how well $E_{A(ji,IRT)}$ is related to the Effort scale of the NASA-TLX.


```{r, echo=FALSE, message=FALSE}

# # Pull ranef for person and item to calculate IRT efforts
# rand <- ranef(fit_1pl)
# 
# rand_person <- data.frame(person = row.names(rand$person), rand$person)
# 
# rand_item <- as.data.frame(rand$item)
# rand_item <- data.frame(beta = rep(rand_item$Estimate.Intercept, times = length(unique(nback_dat$person)))) %>%
#   mutate(item = as.factor(rep(1:length(unique(nback_dat$item)), times=length(unique(nback_dat$person)))),
#          person = rep(rand_person$person, each=length(unique(nback_dat$item)))) %>%
#   select(person, item, beta)
# 
# rand_all <- left_join(rand_person, rand_item, by = "person") %>%
#   rename(
#     theta = "Estimate.Intercept") %>%
#   mutate(beta = beta*-1,
#          irt_effort = if_else(exp(beta) > exp(theta), 1, (exp(beta)/exp(theta)))
#   )
# 
# # recombine with NASA, SV
# comb_effort <- left_join(rand_all, NASA_dat, by = c("person", "item"))
# comb_effort <- left_join(comb_effort, SV_dat, by = c("person", "item"))
# 
# 
# # NASA_effort ~ IRT Effort
# 
# comb_effort <- comb_effort %>% # add upper and lower bounds manually so that data is normalised to them for ordbetareg
#   add_row(Effort = 0) %>%
#   add_row(Effort = 21)
# 
# ordbeta_NASA_effort <- ordbetareg(formula = Effort ~ irt_effort + (irt_effort | person),
#                                   data = comb_effort,
#                                   chains = 4,
#                     iter = 3000, warmup = 1000,
#                     cores = 4,
#                     control = list(adapt_delta = 0.95), inits = 0)
# 
# ordbeta_NASA_effort_p <- comb_effort %>%
#   filter(Effort > 0) %>%
#   # data_grid(irt_effort = seq(from = 0, to = 1, length = 101), person) %>%
#   tidyr::expand(nesting(person),
#                 irt_effort = seq(from = 0, to = 1, length = 101)) %>%
#   add_epred_draws(ordbeta_NASA_effort) %>%
#   ggplot(aes(x = irt_effort*100, y = .epred*100)) +
#   stat_lineribbon(aes(y = .epred*100, fill_ramp = stat(.width)), alpha = 0.8, .width = ppoints(50), fill = "grey") +
#   ggdist::scale_fill_ramp_continuous(range = c(1, 0)) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
#   scale_y_continuous(limits = c(0,100)) +
#   scale_x_continuous(limits = c(0,100)) +
#   labs(title = "IRT (1PL) Estimated Effort and NASA-TLX Effort",
#        subtitle = "Mixed Effects Ordered Beta Regression",
#        y = "NASA-TLX Effort (Ordered Beta Transformation; %)",
#        x = expression("IRT Estimated Effort = exp("~beta~")/exp("~theta~")")) +
#   theme_classic()
# 
# ordbeta_NASA_effort_p


```


```{r, echo=FALSE, message=FALSE}
# # SV ~ IRT Effort
# comb_effort_SV <- comb_effort %>%
#   filter(!is.na(SV)) %>%
#   add_row(SV_effort = 0) %>%
#   add_row(SV_effort = 1)
# 
# ordbeta_SV_effort <- ordbetareg(formula = SV_effort ~ irt_effort + (irt_effort | person),
#                                   data = comb_effort,
#                                   chains = 4,
#                     iter = 3000, warmup = 1000,
#                     cores = 4,
#                     control = list(adapt_delta = 0.95), inits = 0)
# 
# ordbeta_SV_effort_p <- comb_effort_SV %>%
#   filter(SV_effort > 0) %>%
#   # data_grid(irt_effort = seq(from = 0, to = 1, length = 101), person) %>%
#   tidyr::expand(nesting(person),
#                 irt_effort = seq(from = 0, to = 1, length = 101)) %>%
#   add_epred_draws(ordbeta_SV_effort) %>%
#   ggplot(aes(x = irt_effort*100, y = .epred*100)) +
#   stat_lineribbon(aes(y = .epred*100, fill_ramp = stat(.width)), alpha = 0.8, .width = ppoints(50), fill = "grey") +
#   ggdist::scale_fill_ramp_continuous(range = c(1, 0)) +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
#   scale_y_continuous(limits = c(0,100)) +
#   scale_x_continuous(limits = c(0,100)) +
#   labs(title = "IRT (1PL) Estimated Effort and Inverse Relative Subjective Value",
#        subtitle = "Mixed Effects Ordered Beta Regression",
#        y = "Subjective Effort Cost (%)",
#        x = expression("IRT Estimated Effort = exp("~beta~")/exp("~theta~")")) +
#   theme_classic()
# 
# SV_effort_p

```


[^1]: See this nice thesis by Rebecca Freund [_Rasch and Rationality: Scale typologies as applied to Item Response Theory_](https://escholarship.org/uc/item/1vh141kq)
[^2]: [What is (perception of) effort? Objective and subjective effort during attempted task performance](https://www.hormelab.com/what_is_effort/)
[^3]: Free demo of the 2-back task as an example [here](https://www.psytoolkit.org/experiment-library/nback2.html) for those that don't know what this involves... at the higher levels it's pretty tough.
[^4]: The [NASA-TLX](https://humansystems.arc.nasa.gov/groups/tlx/downloads/TLXScale.pdf) is a six item state questionnaire, one of which asks about the effort required i.e., "How hard did you have to work to accomplish your level of performance?". It's not ideal in my opinion given my conceptual definition of perception of effort, but it'll do for current purposes.
[^5]: Westbrook et al. describe it as follows: _"The key feature of this paradigm is that participants choose whether to perform a low-effort task for a small monetary reward or a high-effort task for a larger reward (Figure 1). Multiple choices are made, and the amount offered for the low-effort task is titrated until subjective equivalence is reached (the offers are equally preferred). The additional amount required to make the high- and low-effort task equivalent quantifies the cost of cognitive effort, or the degree to which increased cognitive effort diminishes the value of task engagement. The objective load of the high-effort task can also be varied parametrically. As such, the procedure is formally analogous to the estimation of discounting across a range of delays in delay discounting. Unlike discounting procedures involving hypothetical costs or rewards, participants make choices about tasks that they are actually paid for re-doing, promoting test validity."_
[^6]: It is often assumed that effort is inherently aversive and so the valuation of effort says something about the subjective experience of it. But as Inzlicht et al. have [suggested](https://pubmed.ncbi.nlm.nih.gov/29477776/) effort can be both costly and valued. In fact, some people often seek out effortful experiences. For example, I like to engage in resistance training, and when I do so I deliberately aim to do so with maximum effort (i.e., to task failure). In such a situation the subjective valuation of the effort experienced would not necessarily follow the direction which would be assumed if it were inherently aversive. 
[^7]: As with the previous post I use the {ordbetareg} package that overlays {brms}, from Robert Kubinec [see here](https://osf.io/preprints/socarxiv/2sx6y/) and which does the job of normalising the variable to the [0,1] interval to fit the ordered beta regression model. 

